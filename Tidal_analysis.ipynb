{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKjSbCWA7DPwCD166Wc0vu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhill1/tidal_analysis_workshop/blob/main/Tidal_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Tides are a fundamental part of a number of coastal processes. As sea levels rise, tides will change, and hence our flood risk, coastal geomorphology and ecological systems will also change as a consequence.\n",
        "\n",
        "This Jupyter notebook will take you through the analysis of sea level data to extract tidal information.\n"
      ],
      "metadata": {
        "id": "YfiWSdM-IMgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What to do\n",
        "\n",
        "Run each block of code sequentially. In some places, template code is given for you to edit to carry out your own analysis.\n",
        "\n",
        "There are questions posed along the way to help gain understanding.\n"
      ],
      "metadata": {
        "id": "WOnhi5JHJR8n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9-sW4SyIIv9"
      },
      "outputs": [],
      "source": [
        "# let's install some essential python modules\n",
        "!pip install wget\n",
        "!pip install uptide"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the modules we need\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import wget\n",
        "import os\n",
        "import numpy as np\n",
        "import uptide\n",
        "import pytz\n",
        "import math\n"
      ],
      "metadata": {
        "id": "DARp0s04JzbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have out environment set up. We can create a couple of \"helper\" functions to make life easier later!"
      ],
      "metadata": {
        "id": "6Omwk1iSJ907"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_and_process_data(filename):\n",
        "    tide_data = pd.read_csv(filename, header=None)\n",
        "    tide_data['Date'] = pd.to_datetime(dict(year=tide_data[0], month=tide_data[1], day=tide_data[2], hour=tide_data[3]))\n",
        "    # col 0 is year, col 1 is month, col2 is day, col3 hour\n",
        "    tide_data = tide_data.drop([0,1,2,3], axis = 1)\n",
        "    tide_data = tide_data.rename(columns={4: \"Tide\"})\n",
        "    tide_data = tide_data.set_index('Date')\n",
        "    tide_data = tide_data.mask(tide_data['Tide'] < -300)\n",
        "\n",
        "    return tide_data\n",
        "\n",
        "def extract_single_year_remove_mean(year, data):\n",
        "    year_string_start = str(year)+\"0101\"\n",
        "    year_string_end = str(year)+\"1231\"\n",
        "    year_data = data.loc[year_string_start:year_string_end, ['Tide']]\n",
        "    # remove mean to oscillate around zero\n",
        "    mmm = np.mean(year_data['Tide'])\n",
        "    year_data['Tide'] -= mmm\n",
        "\n",
        "    return year_data"
      ],
      "metadata": {
        "id": "DasQsqDGKDpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use data from the long term tidal record dataset held by the School of Ocean and Earth Science and Technology, University of Hawaii. Some of their tidal records go back over 100 years. We're going to download data for three locations in Australia: Freemantle, WA; Booby Island, QLD; and Fort Denison, NSW."
      ],
      "metadata": {
        "id": "JoBwA-u-KIXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FortDenison_url = \"https://uhslc.soest.hawaii.edu/data/csv/fast/hourly/h333.csv\"\n",
        "BoobyIsland_url = \"https://uhslc.soest.hawaii.edu/data/csv/fast/hourly/h336.csv\"\n",
        "Freemantle_url = \"https://uhslc.soest.hawaii.edu/data/csv/fast/hourly/h175.csv\"\n",
        "urls = [FortDenison_url, BoobyIsland_url, Freemantle_url]\n",
        "\n",
        "# fetch our data and store\n",
        "for url in urls:\n",
        "    file_name = os.path.basename(url) # get the full path to the file\n",
        "    if os.path.exists(file_name):\n",
        "        os.remove(file_name) # if exists, remove it directly\n",
        "    file_name = wget.download(url, out=\".\")"
      ],
      "metadata": {
        "id": "yPSPd6yUKmBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have three csv files which should be stored in your temporary files here (click the little folder symbol to the left and you should see the three .csv files)."
      ],
      "metadata": {
        "id": "FrM5-Y2SKsv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load and store as a pandas dataframe\n",
        "Fort_Denison = read_and_process_data(\"h333.csv\")\n",
        "Booby_Island = read_and_process_data(\"h336.csv\")\n",
        "Freemantle = read_and_process_data(\"h175.csv\")\n"
      ],
      "metadata": {
        "id": "zsAmpvzVK0Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot 1 years' worth of tidal data\n",
        "fig_summary=plt.figure()\n",
        "ax=fig_summary.add_subplot(111)\n",
        "fd = ax.plot(Fort_Denison['Tide'], color=\"blue\", lw=1, label=\"Fort Denison\")\n",
        "bi = ax.plot(Booby_Island['Tide'], color=\"orange\", lw=1, label=\"Booby_Island\")\n",
        "f = ax.plot(Freemantle['Tide'], color=\"red\", lw=1, label=\"Freemantle\")\n",
        "ax.set_xlabel(\"Date\")\n",
        "ax.set_ylabel(\"Water height (mm)\")\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.legend()\n",
        "ax.set_xlim([datetime.date(2008, 1, 1), datetime.date(2008, 12, 31)])\n",
        "fig_summary.tight_layout()"
      ],
      "metadata": {
        "id": "UkUNpsE1K4gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot, though busy, already shows some interesting features. Booby Island has the highest tidal range and shows a clear annual signal. Freemantle has the smallest tidal range and seems fairly constant.\n",
        "\n",
        "Tide gauges often record the water level so can pick up storms and are affected by even small winds blowing onshore for example. This means the data you see might not be \"just tides\", but also some aspect of weather, depending on how the data are processed. In addition, for long term records, the tide gauges will also record sea level rise. All heights are measured above a datum so you also have to be careful comparing raw data from one tide gauge to another.\n",
        "\n",
        "Let's now look at one month in detail:"
      ],
      "metadata": {
        "id": "qv3qOvvMLIFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig_june=plt.figure()\n",
        "ax=fig_june.add_subplot(111)\n",
        "fd = ax.plot(Fort_Denison['Tide'], color=\"blue\", lw=1, label=\"Fort Denison\")\n",
        "bi = ax.plot(Booby_Island['Tide'], color=\"orange\", lw=1, label=\"Booby_Island\")\n",
        "f = ax.plot(Freemantle['Tide'], color=\"red\", lw=1, label=\"Freemantle\")\n",
        "ax.set_xlabel(\"Date\")\n",
        "ax.set_ylabel(\"Water height (mm)\")\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.legend()\n",
        "ax.set_xlim([datetime.date(2008, 6, 1), datetime.date(2008, 7, 1)])\n",
        "fig_june.tight_layout()"
      ],
      "metadata": {
        "id": "j1Y75cGoLcYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now see more of the tidal signals. You may notice Freemantle shows fewer wiggles than the other two locations; this is because it is a diurnal tide: one tide per day. Fort Denison has a clear two tides per day; semi-diurnal. Booby Island normally has two tides per days, but some days, those two tides effectively blend into one (see around the 17th June). This is a mixed diurnal-semi diurnal system.\n",
        "\n",
        "All tidal signals are essentially a mix of multiple sine curves. We know what the frequency of the external forcing is for tides (the rotation of the earth, the movement of the moon around the earth, etc), which allows us to break up the signal into constituent parts: the tidal constituents. These are often given labels such as M2, S2, K1, O1, etc. Each one has a particular frequency as given in the table below.\n",
        "\n",
        "Decription                        |\tDarwin symbol | Period (h) | Speed (Â°/h)\n",
        "----------------------------------|---------------|------------|------------\n",
        "Principal lunar semidiurnal\t      | M2            | 12.4206012 | 28.9841042\n",
        "Principal solar semidiurnal\t      | S2\t          | 12         |\t30\t      \n",
        "Lunar diurnal\t                    | K1\t          | 23.9344721 |\t15.0410686\n",
        "Lunar diurnal\t                    | O1\t          | 25.8193387 |\t13.9430356\n",
        "Lunisolar semidiurnal\t            | K2\t          |11.96723606 |\t30.0821373\n",
        "Larger lunar elliptic semidiurnal\t| N2\t          | 12.6583475 |\t28.4397295\n",
        "\n",
        "There are over 400 different contiuents, but 60-ish is considered enough for accurate tidal predictions, but fewer still can be used for useful tidal predictions. The tidal signal can then be reconstructed by summing sine curves of the correct frequency and amplitude (and phase) to recreate and then predict the tides. At each location the amplitude and phase will be different.\n",
        "\n",
        "Let's add up some sine curves to make something like the tide signals above.\n"
      ],
      "metadata": {
        "id": "Oy10MXruLbXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sine curves\n",
        "\n",
        "Sine cuves can be generalised to the formula:\n",
        "\n",
        "$y = A sin (Bx+C) + D$\n",
        "\n",
        "$A$ is the amplitude, $2\\pi/B$ is the period, $C$ is the phase shift and $D$ is the vertical shift. We know the period (from the table above!) and $D$ is not relevant here, so we have two parameters to play with: $A$ and $C$."
      ],
      "metadata": {
        "id": "cCZzrh4DzI5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_m2 = 0.53\n",
        "B_m2 = 12.4206012 # hours\n",
        "C_m2 = 0\n",
        "\n",
        "times = np.arange(0,24*14,0.5) # 14 days in hours\n",
        "sin_curve = A_m2*np.sin(2*math.pi/B_m2*times + C_m2)\n",
        "\n",
        "plt.plot(times,sin_curve)\n",
        "plt.xlabel(\"Hours\")\n",
        "plt.ylabel(\"Water height (m)\")"
      ],
      "metadata": {
        "id": "1B7Rt9jqggt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now add an S2 curve on that\n",
        "A_s2 = 0.23\n",
        "B_s2 = 12\n",
        "C_s2 = math.pi/2\n",
        "\n",
        "sin_curve = A_m2*np.sin(2*math.pi/B_m2*times + C_m2) + \\\n",
        "            A_s2*np.sin(2*math.pi/B_s2*times + C_s2)\n",
        "plt.plot(times,sin_curve)\n",
        "plt.xlabel(\"Hours\")\n",
        "plt.ylabel(\"Water height (m)\")"
      ],
      "metadata": {
        "id": "PDbMOnu71p1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above shows what in effect is spring and neap tide using just two components, with different amplitudes and phases (and frequencies/periods).\n",
        "\n",
        "We can extract constituents from a tidal signal like those plotted above using least squares regression analysis to work out what the tidal constiuents are. Let's do that now to pull out the common consituents from our tidal data."
      ],
      "metadata": {
        "id": "buJ0T2gGghNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's first pull out a single year's worth of data\n",
        "# and remove the mean value so the tides oscillate across zero\n",
        "FD_2008 = extract_single_year_remove_mean(2008, Fort_Denison)\n",
        "BI_2008 = extract_single_year_remove_mean(2008, Booby_Island)\n",
        "F_2008 = extract_single_year_remove_mean(2008, Freemantle)\n"
      ],
      "metadata": {
        "id": "gFizRPnlfGbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use the module uptide to work out the tidal constiuents\n",
        "# More on uptide: https://github.com/stephankramer/uptide\n",
        "import uptide\n",
        "# we create a Tides object with a list of the consituents we want.\n",
        "tide = uptide.Tides(['M2'])\n",
        "# We then set out start time. All data must then be in second since this time\n",
        "tide.set_initial_time(datetime.datetime(2008,1,1,0,0,0))\n",
        "# so let's swap our dates for seconds since midnight 1/1/2008.\n",
        "# Note the 1e9 (the int64 seconds epoch in numpy is multiplied by this for some reason)\n",
        "seconds_since = (FD_2008.index.astype('int64').to_numpy()/1e9) - datetime.datetime(2008,1,1,0,0,0).timestamp()\n",
        "# We then send the elevation data (our tides) and time in seconds to uptide\n",
        "# and do the harmonic analysis\n",
        "amp,pha = uptide.harmonic_analysis(tide, FD_2008['Tide'].to_numpy()/1000, seconds_since)\n",
        "\n",
        "# uptide returns the amplitudes as a list (in the order of the constiuents listed above) and the phases (in radians)\n",
        "print(amp, pha)\n"
      ],
      "metadata": {
        "id": "URbRvyTgfaTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above numbers are the tidal amplitude for the M2 constiuent at Fort Denison (0.5013 m) and the phase (5.366 radians). We can look up what the actual numbers are for Fort Denison (exercise for the reader!). However, we've forgotten something: *timezones*!\n",
        "\n",
        "We also need to account for the timezone of the data. The phase is measured relative to UTC/GMT. We therefore need to tell the analysis the time data is in the Sydney timezone."
      ],
      "metadata": {
        "id": "-JAGMQBgbM6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tz = pytz.timezone(\"Australia/Sydney\")\n",
        "tide.set_initial_time(datetime.datetime(2008,1,1,0,0,0))\n",
        "seconds_since = (FD_2008.index.astype('int64').to_numpy()/1e9) - datetime.datetime(2008,1,1,0,0,0,tzinfo=tz).timestamp()\n",
        "\n",
        "amp,pha = uptide.harmonic_analysis(tide, FD_2008['Tide'].to_numpy()/1000, seconds_since)\n",
        "print(amp,pha)"
      ],
      "metadata": {
        "id": "fFOVdnYD604k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have the phase, in radians, relative to UTC/GMT, but taking into account the timezone. In the code box below, write code, using the box above as a template, to get the amplitudes and phase for M2 only at Booby Island and Freemantle."
      ],
      "metadata": {
        "id": "OvB88Bsk7CRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code to obtain the M2 component from Booby Island and Freemantle. Rember the timezone!\n",
        "# tz = pytz.timezone(\"Australia/Perth\")\n",
        "# tz = pytz.timezone(\"Australia/Lindeman\")"
      ],
      "metadata": {
        "id": "FSIQrGiM7BsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens when we want multiple constiuents? The first thing we need to consider is how long our data record is. Consituents that have a period/frequency that is close together need a longer dataset to be able to seperate them out. We can use something called the Rayleigh Critereon to work out how long a record we need."
      ],
      "metadata": {
        "id": "GYGEwWia9Hai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "constituents  = ['M2', 'S2', 'N2', 'K2', 'O1', 'P1', 'Q1', 'M4']\n",
        "print(uptide.select_constituents(constituents,15*24*60*60)) # This is 15 days in seconds"
      ],
      "metadata": {
        "id": "F0Rjle3v9d03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we get back is that we can't resolve the N2, K2 and Q1 from the list with 15 days worth of data. What if we had 30 days?"
      ],
      "metadata": {
        "id": "Ws3uTBJ39hq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "constituents  = ['M2', 'S2', 'N2', 'K2', 'O1', 'P1', 'Q1', 'M4']\n",
        "print(uptide.select_constituents(constituents,30*24*60*60)) # This is 15 days in seconds"
      ],
      "metadata": {
        "id": "-7bKL4fT9qT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nope! K2 is still not able to be resolved from 30 days worth of data. How many days would we need?"
      ],
      "metadata": {
        "id": "7CU77K-R9vJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tide = uptide.Tides(constituents)\n",
        "print(tide.get_minimum_Rayleigh_period()/86400.)"
      ],
      "metadata": {
        "id": "q1Morb9M93-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "182.6 days worth of data to be able to work out the constituents listed above. So with our year of data we should be fine!"
      ],
      "metadata": {
        "id": "xuzNnl14-MOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tz = pytz.timezone(\"Australia/Sydney\")\n",
        "tide.set_initial_time(datetime.datetime(2008,1,1,0,0,0))\n",
        "seconds_since = (FD_2008.index.astype('int64').to_numpy()/1e9) - datetime.datetime(2008,1,1,0,0,0,tzinfo=tz).timestamp()\n",
        "\n",
        "amp,pha = uptide.harmonic_analysis(tide, FD_2008['Tide'].to_numpy()/1000, seconds_since)\n",
        "print(amp, pha)"
      ],
      "metadata": {
        "id": "OrPP1qen-YE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At Fort Denison our amplitudes and phases are:\n",
        "\n",
        "\n",
        "*   M2: 0.503m and 4.182 radians\n",
        "*   S2: 0.125m and 4.599 radians\n",
        "*   N2: 0.115 and 3.93 radians\n",
        "*   K2: 0.036 and 4.27 radians\n",
        "*   O1: 0.097 and 1.42 radians\n",
        "*   P1: 0.043 and 1.99 radians\n",
        "*   Q1: 0.020 and 1.016 radians\n",
        "*   M4: 0.003 and 2.09 radians\n",
        "\n",
        "We could plot those using a bunch of sine curves and compare to our data...\n",
        "\n",
        "Fortunately for us, `uptide` also contains functions to plot a theoretical tidal curve from a number of phases and amplitudes for given constiuents.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jQbmBQFk-k4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0, 365*24*3600, 1800) # 1 year in 1800 second intervals\n",
        "eta = tide.from_amplitude_phase(amp, pha, t)\n",
        "fig_summary=plt.figure()\n",
        "ax=fig_summary.add_subplot(111)\n",
        "# note we use seconds since as t (for the theoretical plot) is also in seconds\n",
        "fd = ax.plot(seconds_since/86400, FD_2008['Tide']/1000, color=\"blue\", lw=1, label=\"Fort Denison\")\n",
        "theoretical = ax.plot(t/86400, eta, color=\"orange\", lw=1, label=\"Theoretical\")\n",
        "ax.set_xlabel(\"Days\")\n",
        "ax.set_ylabel(\"Water height (m)\")\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "# uncomment line below and rerun to see a zoom in\n",
        "#ax.set_xlim([14, 44]) # only plot 30 days worth\n",
        "ax.legend()\n",
        "fig_summary.tight_layout()"
      ],
      "metadata": {
        "id": "Q9qGMPaVW8ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: Create similar plots for Booby Island and Freemantle in the semi-completed code blocks below."
      ],
      "metadata": {
        "id": "U2HxTV97ZRoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Booby Island\n",
        "\n",
        "# Analyse the tides and store in amp, pha\n",
        "\n",
        "t = np.arange(0, 365*24*3600, 1800) # 1 year in 1800 second intervals\n",
        "eta = tide.from_amplitude_phase(amp, pha, t)\n",
        "fig_summary=plt.figure()\n",
        "ax=fig_summary.add_subplot(111)\n",
        "# add the res tof the plotting code"
      ],
      "metadata": {
        "id": "7kgrCPrAZYPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freemantle\n",
        "\n",
        "# Analyse the tides and store in amp, pha\n",
        "\n",
        "t = np.arange(0, 365*24*3600, 1800) # 1 year in 1800 second intervals\n",
        "eta = tide.from_amplitude_phase(amp, pha, t)\n",
        "fig_summary=plt.figure()\n",
        "ax=fig_summary.add_subplot(111)\n",
        "# add the res tof the plotting code"
      ],
      "metadata": {
        "id": "dc6W5dTeZZAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions to think about:\n",
        "\n",
        "\n",
        "1.   None of our theoretical tidal curves are perfect. Why?\n",
        "2.   How would you go about predicting tides into the future?\n",
        "\n"
      ],
      "metadata": {
        "id": "z1sSgqwNZcmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tidal modelling\n",
        "\n",
        "Whilst the tidal gauge analysis is useful (and widely used!) it is ony one dimensional. It will only give information at a single location through time. Tides are three dimensional: they also vary in space, which we can see by looking at different tide gauges. How do we fill in the space between tide gauges? Numerical modelling of the tides is the answer to that question! There are a large number of tidal models available that can simulate local, regional or global tides. Most use the Shallow Water Equations (SWE), which simulates the water surface moving up and down due to gravitational forcing and the flow of water that generates. SWE models have no vertical structure though; they simulate the ocean and seas as a single layer with a depth-averaged velocity. But because of that they are quick (relatively speaking) to run.\n",
        "\n",
        "The big advantage of a numerical model is that you can ask hypothetical questions, such as \"how will the tides change as sea-level rises?\". A number of studies have done just that and found that changes in the tidal range in places will be up to 10% of the sea-level rise. This alters your flood risk at the coast by an additional 10% (either increase or decrease, but obviously a 10% increase is bad!).\n",
        "\n",
        "We can't run a detailed model in Google Colab unfortunately, but we can have a look at the results from one and compare to tide gauges!\n",
        "\n",
        "[In our recent paper on the future tides on the GBR](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021JC017823), we ran tidal models for 90 simulated days (which took a few hundred cores a couple of weeks to run). We validated the model against tide gauges for the present day sea level, and then re-ran the model with 0.43 and 1.1 m of relative sea-level rise.\n",
        "\n",
        "We're going to pull data from a station that's in our model and also grab data for that virtual tide gauge in the model and compare."
      ],
      "metadata": {
        "id": "8SMpcALFZqBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "townsville_url = \"https://uhslc.soest.hawaii.edu/data/csv/fast/hourly/h334.csv\"\n",
        "model_townsville_url = \"https://raw.githubusercontent.com/jhill1/tidal_analysis_workshop/main/Mawson_et_al_Townsville.csv\"\n",
        "\n",
        "file_name = os.path.basename(townsville_url) # get the full path to the file\n",
        "if os.path.exists(file_name):\n",
        "  os.remove(file_name) # if exists, remove it directly\n",
        "file_name = wget.download(townsville_url, out=\".\")\n",
        "\n",
        "Townsville = read_and_process_data(\"h334.csv\")\n",
        "\n",
        "file_name = os.path.basename(model_townsville_url) # get the full path to the file\n",
        "if os.path.exists(file_name):\n",
        "  os.remove(file_name) # if exists, remove it directly\n",
        "file_name = wget.download(model_townsville_url, out=\".\")\n",
        "\n",
        "# Load in model data and reformat to match the tide gauge data\n",
        "Model_Townsville = pd.read_csv(\"Mawson_et_al_Townsville.csv\")\n",
        "Model_Townsville['Date'] = pd.to_datetime(Model_Townsville['Time (s)'],\n",
        "                                          unit='s',\n",
        "                                          origin=datetime.datetime(2000,1,1,0,0,0))\n",
        "Model_Townsville = Model_Townsville.rename(columns={'Height (m)': 'Tide'})\n",
        "Model_Townsville = Model_Townsville.drop('Time (s)', axis=1)\n",
        "Model_Townsville = Model_Townsville.set_index('Date')\n",
        "# remove first 5 days (spin-up of the model) to leave 85 days of data\n",
        "Model_Townsville = Model_Townsville['2000-01-05':'2000-03-31']\n",
        "\n",
        "# Our model ran from 1st Jan 2000, so let's pull the year 2000 from the real data\n",
        "Townsville_2000 = extract_single_year_remove_mean(2000, Townsville)\n",
        "Townsville_2000['Tide'] /= 1000\n",
        "\n",
        "# restrict to 85 days to match model\n",
        "Townsville_2000 = Townsville_2000['2000-01-05':'2000-03-31']\n"
      ],
      "metadata": {
        "id": "285E4nXUKQwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_model=plt.figure()\n",
        "ax=fig_model.add_subplot(111)\n",
        "fd = ax.plot(Model_Townsville['Tide'], color=\"blue\", lw=1, label=\"Model\")\n",
        "bi = ax.plot(Townsville_2000['Tide'], color=\"orange\", lw=1, label=\"Tide Gauge\")\n",
        "ax.set_xlabel(\"Date\")\n",
        "ax.set_ylabel(\"Water height (mm)\")\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.legend()\n",
        "fig_june.tight_layout()"
      ],
      "metadata": {
        "id": "Den8C3pFPzij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's analyse the model data and measured data to see how good the model is. We can see from the graph above it's not perfect, so how close is it?\n",
        "\n",
        "The model was forced with the following consituents: M2, S2, N2, K2, K1, O1, P1, Q1, M4, MS4 and MN4\n"
      ],
      "metadata": {
        "id": "A6QVjIpeU0Bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check rayleigh criterion for which constiuents\n",
        "constituents  = ['M2', 'S2', 'N2', 'K2', 'K1', 'O1', 'P1', 'Q1', 'M4', 'MS4', 'MN4']\n",
        "print(uptide.select_constituents(constituents,85*24*60*60))\n"
      ],
      "metadata": {
        "id": "gL8VR0k7Uwpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note I've adjusted the order to pull out the more important consituents first,\n",
        "# removing the ones we can't resolve\n",
        "constituents  = ['M2', 'S2', 'K1', 'O1', 'N2', 'Q1', 'M4', 'MS4', 'MN4']\n",
        "tide = uptide.Tides(constituents)\n",
        "tide.set_initial_time(datetime.datetime(2000,1,1,0,0,0))\n",
        "tz = pytz.timezone(\"Australia/Lindeman\")\n",
        "seconds_since = (Model_Townsville.index.astype('int64').to_numpy()/1e9) - datetime.datetime(2000,1,1,0,0,0,tzinfo=tz).timestamp()\n",
        "\n",
        "m_amp,m_pha = uptide.harmonic_analysis(tide, Model_Townsville['Tide'].to_numpy(), seconds_since)\n",
        "# The amplitudes and pahses are printed in the same order as the constiuents listed above\n",
        "print(constituents)\n",
        "print(m_amp)\n",
        "print(np.degrees(m_pha))"
      ],
      "metadata": {
        "id": "NSqox-loVKX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The above is the model; what about the data?\n",
        "seconds_since = (Townsville_2000.index.astype('int64').to_numpy()/1e9) - datetime.datetime(2000,1,1,0,0,0,tzinfo=tz).timestamp()\n",
        "\n",
        "amp,pha = uptide.harmonic_analysis(tide, Townsville_2000['Tide'].to_numpy(), seconds_since)\n",
        "print(constituents)\n",
        "print(amp)\n",
        "print(np.degrees(pha))"
      ],
      "metadata": {
        "id": "Cr2nZOr8We-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Australian Hydrological Office has the following data for Townsville, which can compare to the model and a tide gauge:\n",
        "\n",
        "Amplitudes:\n",
        "\n",
        "Data |Q1 amp | O1 amp | K1 amp | N2 amp | M2 amp | S2 amp |\n",
        "-----|-------|--------|--------|--------|--------|--------|\n",
        "AHO  | 0.0296| 0.1638 | 0.3389 | 0.2374 | 0.7418 | 0.4268 |\n",
        "Model| 0.0315| 0.1631 | 0.3331 | 0.2463 | 0.7808 | 0.4490 |\n",
        "Gauge| 0.0306| 0.1724 | 0.3500 | 0.2232 | 0.7396 | 0.4276 |\n",
        "\n",
        "Phases:\n",
        "\n",
        " Data    | Q1     | O1    | K1     | N2     | M2     | S2    |\n",
        "---------|--------|-------|--------|--------|--------|-------|\n",
        "AHO      | 126.73 | 152.17| 188.14 | 255.76 | 278.09 | 247.61|\n",
        "Model    | 128.58 | 143.68| 193.40 | 242.15 | 264.93 | 244.98|\n",
        "Gauge    | 121.55 | 148.07| 202.95 | 247.82 | 274.49 | 255.75|\n",
        "\n",
        "You can see that the model performs well; in most cases being closer than the tide gauge data to the AHO constituents. Why would this be the case?\n"
      ],
      "metadata": {
        "id": "-8MjuYSBZ6NW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Tree Island**\n",
        "\n",
        "The model also simulates One Tree where the UoS reasearch station is situated. Using the code above, can you extract the modelled tidal consituents for OTI? The code below will get you started, but use the code for Townsville, above, to finish it off."
      ],
      "metadata": {
        "id": "QsnOLkUH7xxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat above for OTI (but we have no long term tidal gauge station there)\n",
        "model_oti_url = \"https://raw.githubusercontent.com/jhill1/tidal_analysis_workshop/main/Mawson_et_al_OTI.csv\"\n",
        "file_name = os.path.basename(model_oti_url) # get the full path to the file\n",
        "if os.path.exists(file_name):\n",
        "  os.remove(file_name) # if exists, remove it directly\n",
        "file_name = wget.download(model_oti_url, out=\".\")\n",
        "\n",
        "# Load in model data and reformat to match the tide gauge data\n",
        "Model_OTI = pd.read_csv(\"Mawson_et_al_OTI.csv\")"
      ],
      "metadata": {
        "id": "FnbAAuhk8Efw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AHO has the following data for OTI. How close is the model? Fill in your analysis results in the table below (double click this cell and complete the table).\n",
        "\n",
        "Amplitudes:\n",
        "\n",
        "Data |Q1 amp | O1 amp | K1 amp | N2 amp | M2 amp | S2 amp |\n",
        "-----|-------|--------|--------|--------|--------|--------|\n",
        "AHO  | 0.0264| 0.1554 | 0.2832 | 0.1905 | 0.923  | 0.3378 |\n",
        "Model|       |        |        |        |        |        |\n",
        "\n",
        "\n",
        "Phases:\n",
        "\n",
        " Data    | Q1     | O1    | K1     | N2     | M2     | S2    |\n",
        "---------|--------|-------|--------|--------|--------|-------|\n",
        "AHO      | 77.60  | 114.65| 153.43 | 219.90 | 248.08 | 254.41|\n",
        "Model    |        |       |        |        |        |       |\n",
        "\n",
        "Finally, we can plot the model against the theoretical tides, as we did above. Complete the code below, using the table above, to plot both the model and tide gauge reconstruction at OTI, and compare."
      ],
      "metadata": {
        "id": "GJF0qgg_C5IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0, 85*24*3600, 1800) # 85 days in 1800 second intervals\n",
        "# Set up our constiuents\n",
        "constituents  = ['M2', 'S2', 'K1', 'O1', 'N2', 'Q1']\n",
        "# add in two arrays for amplitude and phase\n",
        "amp = [ ]\n",
        "pha = [ ]\n",
        "#\n",
        "eta = tide.from_amplitude_phase(amp, pha, t)\n",
        "fig_summary=plt.figure()\n",
        "ax=fig_summary.add_subplot(111)\n",
        "seconds_since = (Model_Townsville.index.astype('int64').to_numpy()/1e9) - datetime.datetime(2000,1,1,0,0,0,tzinfo=tz).timestamp()\n",
        "# note we use seconds since as t (for the theoretical plot) is also in seconds\n",
        "fd = ax.plot(seconds_since/86400, Model_OTI['Tide'], color=\"blue\", lw=1, label=\"Model\")\n",
        "theoretical = ax.plot(t/86400, eta, color=\"orange\", lw=1, label=\"Theoretical\")\n",
        "ax.set_xlabel(\"Days\")\n",
        "ax.set_ylabel(\"Water height (m)\")\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.legend()\n",
        "fig_summary.tight_layout()"
      ],
      "metadata": {
        "id": "gAObf1fmD7RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "This notbook goes through the basics of analysing tidal gauge data and comparing to virtual tide gauges from a model. Understanding this will help you interpret tidal gauge data, but also how complex a tidal model can be and how helpful they are.\n",
        "\n",
        "[I've created a fully completed version of this notebook here](https://github.com/jhill1/tidal_analysis_workshop/blob/main/Tidal_analysis_answers.ipynb) if you need to find any answers or check your code against mine.\n",
        "\n",
        "You can download a copy of the notebook or store to your google drive or github."
      ],
      "metadata": {
        "id": "GKvfE_6YEqwh"
      }
    }
  ]
}